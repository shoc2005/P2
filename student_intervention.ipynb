{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "This is a classification problem. We need to classify students into two groups: ones who need and do not needed early intervention (two-class classification), hence the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n",
    "\n",
    "_To execute a code cell, click inside it and press **Shift+Enter**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "#Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1\n",
    "n_passed = pd.value_counts(student_data.passed == \"yes\")[True]\n",
    "n_failed = pd.value_counts(student_data.passed == \"yes\")[False]\n",
    "grad_rate = float(n_passed)/(n_passed + n_failed)*100\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "global X_all\n",
    "global y_all\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = pd.DataFrame(student_data[target_col])  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "    #print outX.columns[:]\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "global X_all\n",
    "global y_all\n",
    "X_all = preprocess_features(X_all)\n",
    "y_all = preprocess_features(y_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size=num_test, \n",
    "                                                    train_size=num_train,\n",
    "                                                    stratify = y_all)\n",
    "y_train = y_train.as_matrix().reshape((y_train.shape[0]))\n",
    "y_test = y_test.as_matrix().reshape((y_test.shape[0]))\n",
    "    \n",
    "# X_train, y_train, X_test, y_test = next_batch(rs, train_size = num_train ,test_size = num_test, keep_test_set_constant=True)\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What is the theoretical O(n) time & space complexity in terms of input size?\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.005\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "    return \"{:.5f}\".format(end - start)\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "\n",
    "def create_classifier(type_of = \"Tree\", weights = None):\n",
    "    if type_of == \"Tree\":\n",
    "        return tree.DecisionTreeClassifier(class_weight=weights) #used parameter class_weight because dataset not balanced\n",
    "    elif type_of == \"SVM\":\n",
    "        return svm.SVC(class_weight=weights) #used parameter class_weight because dataset not balanced\n",
    "    elif type_of == \"GrBoost\":\n",
    "        return GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=3)\n",
    "    else:\n",
    "        raise ValueError(\"Classifier not found\", type_of)\n",
    "        \n",
    "\n",
    "clf = create_classifier(\"Tree\")\n",
    "train_classifier(clf, X_train, y_train)\n",
    "print clf  # you can inspect the learned model by printing it\n",
    "#print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00071\n",
      "F1 score for training set: 1.000 in 0.00071 sec\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nPrediction time (secs): {:.5f}\".format(end - start)\n",
    "    return f1_score(target, y_pred), \"{:.5f}\".format(end - start)\n",
    "\n",
    "train_f1_score, time_ = predict_labels(clf, X_train, y_train)\n",
    "print \"F1 score for training set: {:.3f} in {} sec\".format(train_f1_score, time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00059\n",
      "F1 score for test set: (0.69421487603305776, '0.00059')\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "$$\\newline$$**Complexity**\n",
    "\n",
    "Decision Trees in general need: $$O(n_{samples} \\times n_{features} \\times \\log n_{samples}).$$ to construct balanced binary tree and query time: $$O(\\log n_{samples}).$$ For the project`s problem complexity is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity for construction O(31890) for 100 samples\n",
      "Complexity for query O(6) for 100 samples\n"
     ]
    }
   ],
   "source": [
    "samples_ = 100\n",
    "print \"Complexity for construction O({:d}) for {:d} samples\".format(int(samples_*48*np.log2(samples_)), samples_)\n",
    "print \"Complexity for query O({:d}) for {:d} samples\".format(int(np.log2(samples_)), samples_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newline$$**General applications**\n",
    "\n",
    "Decision-trees are best suited to problems with following characteristics:\n",
    "* Samples are represented by attribute-value pairs. Each feature takes on a small number of disjointed possible values (e.g., man, woman).\n",
    "* The best of the two possible output values.\n",
    "* Problems with disjunctive descriptions.\n",
    "* The training data may contain errors. Decision-tree learning methods are robust for errors.\n",
    "* The training data may lack attribute data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strengths and weaknesses \n",
    "$$\\newline$$_Strengths_:\n",
    "\n",
    "* Simple to understand and to interpret, especially using graphic representation.\n",
    "* White box – the learned model will be explained using the Boolean logic.\n",
    "* Data preparation is not very hard. There is no need for data normalization, dummy and empty value filtering.\n",
    "* The computation cost is relatively low - logarithmic for tree-training and prediction.\n",
    "* It is possible to validate the model using statistical tests.\n",
    "\n",
    "\n",
    "$$\\newline$$_Weaknesses_:\n",
    "\n",
    "* The decision-tree learners create biased trees if some classes dominate. Each class will need either balanced training data for every class or equal number of samples.\n",
    "* Usually decision-tree learners generate overfitted models; and to prevent the depth of max and minimum number of samples, a leaf node is necessary.\n",
    "* Small variations of data might result in a greneration of completely different trees.\n",
    "* Learning an optimal decision-tree is a, NP-problem. In practice, heuristic methods are generally used, yet these do not  guarantee the production of a globally optimal tree (to avoid these multiple decision-trees, randomly sampled features and samples will be used ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Student feature dataset contains NaN or empty values ? False\n",
      "Is Student label dataset contains NaN or empty values ? False\n",
      "Weights of data balance:\n",
      "Training data: {0: 0.33, 1: 0.67}\n",
      "Testing data: {0: 0.3263157894736842, 1: 0.6736842105263158}\n"
     ]
    }
   ],
   "source": [
    "def check_of_empty_values(data_set): \n",
    "    #create empty Data frame for broken data (NaN or empty)\n",
    "    return data_set.isnull().values.any()\n",
    "\n",
    "\n",
    "def get_labels_balance(data_set):\n",
    "    #coutn labels in training or testing set and return label weights\n",
    "    unique, counts = np.unique(data_set, return_counts=True)\n",
    "    label_weights = {}\n",
    "    for i in range(0, unique.shape[0]):\n",
    "        label_weights[unique[i]] = float(counts[i])/data_set.shape[0]\n",
    "    return label_weights\n",
    "\n",
    "\n",
    "print \"Is Student feature dataset contains NaN or empty values ?\", check_of_empty_values(X_all)\n",
    "print \"Is Student label dataset contains NaN or empty values ?\", check_of_empty_values(y_all)\n",
    "print \"Weights of data balance:\"\n",
    "print \"Training data:\", get_labels_balance(y_train)\n",
    "print \"Testing data:\", get_labels_balance(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Justification\n",
    "Decision-Trees will be used for classification and regression problems that have either single or multi-variable output. Since DT is the white box, it is possible to explain the predicted results; and it may be useful for staff.\n",
    "\n",
    "Observing the students data, the DT also may be applied to such a problem because:\n",
    "* most of attributes values are two-pared;\n",
    "* the prediction value belongs for the two classes;\n",
    "* the dataset was not specially prepared (excluding data-type conversion to numbers and using dummy variables).\n",
    "\n",
    "Although the dataset is not balanced, it may be mitigated by using label_weights parameter for a classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00028\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00029\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00030\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00026\n",
      "Training DecisionTreeClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00035\n",
      "Predicting labels using DecisionTreeClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00027\n",
      "\n",
      "Decision Tree training results\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.744526            1   100   0.00029    0.00163\n",
      "2    0.781955            1   200   0.00026    0.00225\n",
      "3    0.688000            1   300   0.00027    0.00348\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    #print \"------------------------------------------\"\n",
    "    #print \"Training set size: {}\".format(len(X_train))\n",
    "    tr_weights = get_labels_balance(y_train)\n",
    "    time_str = train_classifier(clf, X_train, y_train)\n",
    "    tr_pred = predict_labels(clf, X_train, y_train)\n",
    "    #print \"F1 score for training set: {}\".format(tr_pred)\n",
    "    ts_pred = predict_labels(clf, X_test, y_test)\n",
    "    #print \"F1 score for test set: {}\".format(ts_pred)\n",
    "    return [{\"Size\":len(X_train), \"Time\":time_str, \"F1_training\":tr_pred, \"F1_testing\":ts_pred}]\n",
    "\n",
    "#Create Pandas table\n",
    "def append_value(frame, dict_values, i):\n",
    "    if type(frame) is pd.DataFrame:\n",
    "        new_frame = pd.DataFrame(dict_values, index=[i])\n",
    "        return pd.concat([frame, new_frame])\n",
    "    else:\n",
    "        return pd.DataFrame(dict_values, index=[i])\n",
    "        \n",
    "\n",
    "# TODO: Run the helper function above for desired subsets of training data\n",
    "# Note: Keep the test set constant\n",
    "training_set_sizes = [100, 200, 300]\n",
    "tree_table = None\n",
    "i = 1\n",
    "for set_size in training_set_sizes:\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, train_size=set_size, random_state=45)\n",
    "    #X_train, y_train, X_test, y_test = next_batch(rs, train_size=set_size, test_size=num_test, keep_test_set_constant=True)\n",
    "\n",
    "    # Create Decision-tree classifier and use label weights\n",
    "    lab_weights = get_labels_balance(y_train[:set_size])\n",
    "    clf = create_classifier(\"Tree\", weights=lab_weights)\n",
    "    train_time = train_classifier(clf, X_train[:set_size], y_train[:set_size])\n",
    "    #print X_train[:set_size].shape\n",
    "    f1_training, tr_time = predict_labels(clf, X_train[:set_size], y_train[:set_size])\n",
    "    f1_testing, ts_time = predict_labels(clf, X_test, y_test)\n",
    "    row = {\"Size\":set_size, \"F1_training\":f1_training, \"F1_testing\":f1_testing, \"Time train\":train_time, \"Time test\":ts_time}\n",
    "    tree_table = append_value(tree_table, row, i)\n",
    "    i += 1\n",
    "\n",
    "# Result of Decision Tree\n",
    "print \"\\nDecision Tree training results\\n\", tree_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "The increase of the training time has approximately the same rate as the increase of the training size. The testing time fluctuates on the same level. The model for all the training sets appears overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "#### Complexity.\n",
    "\n",
    "The core of SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data.\n",
    "The Support Vector Machines for scipy implementation needs to be between $$O(n_{features} \\times n^{2}_{samples})$$ and $$O(n_{features} \\times n^{3}_{samples})$$\n",
    "For the project's problem, the complexity is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity for construction O(4.800e+05) for 100 samples\n",
      "Complexity for query O(4.800e+07) for 100 samples\n"
     ]
    }
   ],
   "source": [
    "samples_ = 100\n",
    "print \"Complexity for construction O({:.3e}) for {:d} samples\".format(int(48*samples_**2), samples_)\n",
    "print \"Complexity for query O({:.3e}) for {:d} samples\".format(int(48*samples_**3), samples_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General applications.\n",
    "\n",
    "The Support Vector Machines (SVMs) is a set of supervised learning methods used for classification, regression, and detection of outliers. It is effective in high dimensional spaces. It is still effective in cases where the number of dimensions is greater than the number of samples. It uses a subset of training points in the decision function (called support vectors), thus being also memory-efficient.\n",
    "\n",
    "\n",
    "#### Strengths and weaknesses\n",
    "_Strengths_:\n",
    "\n",
    "- Effective in high dimensional spaces.\n",
    "- Effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, yet it is also possible to specify custom kernels.\n",
    "\n",
    "\n",
    "_Weakness_:\n",
    "\n",
    "- If the number of features is much greater than the number of samples, the method is likely to result in poor performance.\n",
    "- The SVMs does not directly provide estimates of probability, which are calculated using an expensive five-fold cross-validation (see Scores and probabilities below).\n",
    "- The Support Vector Machine algorithms are not scale-invariant.\n",
    "\n",
    "\n",
    "#### Justification\n",
    "\n",
    "- The number of features is relatively large in comparison to the number of samples.\n",
    "- The SVM will be used for a two-class problem.\n",
    "- The prediction will use a relatively small amount of memory and will be quick, since only support vectors will be stored.\n",
    "- The SVM will also be used for classification problems.\n",
    "- Kernel function can express domain knowledge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00182\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00159\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.007\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00523\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00260\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.014\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.01070\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00362\n",
      "\n",
      "SVM training results\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.800000     0.901961   100   0.00159    0.00259\n",
      "2    0.812903     0.855305   200   0.00260    0.00721\n",
      "3    0.818182     0.845666   300   0.00362    0.01406\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "training_set_sizes = [100, 200, 300]\n",
    "svm_table = None\n",
    "i = 1\n",
    "for set_size in training_set_sizes:\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, train_size=set_size, random_state=475)\n",
    "    #X_train, y_train, X_test, y_test = next_batch(rs, train_size=set_size, test_size=num_test, keep_test_set_constant=True)\n",
    "    \n",
    "    # Create Decision-tree classifier and use label weights\n",
    "    lab_weights = get_labels_balance(y_train[:set_size])\n",
    "    clf = create_classifier(\"SVM\")\n",
    "    \n",
    "    \n",
    "    train_time = train_classifier(clf, X_train[:set_size], y_train[:set_size])\n",
    "    f1_training, tr_time = predict_labels(clf, X_train[:set_size], y_train[:set_size])\n",
    "    f1_testing, ts_time = predict_labels(clf, X_test, y_test)\n",
    "    row = {\"Size\":set_size, \"F1_training\":f1_training, \"F1_testing\":f1_testing, \"Time train\":train_time, \"Time test\": ts_time}\n",
    "    svm_table = append_value(svm_table, row, i)\n",
    "    i += 1\n",
    "\n",
    "# SVM training results\n",
    "print \"\\nSVM training results\\n\", svm_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary.\n",
    "The training time increases very rapidly in the case of an increasing training set. See the calculation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Times 6.963\n"
     ]
    }
   ],
   "source": [
    "print \"Times {:.3f}\".format(float(svm_table[\"Time train\"].iloc[2])/float(svm_table[\"Time train\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing time will increase, yet with a smaller rate than the training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "#### Complexity.\n",
    "\n",
    "The algorithm for the Boosting Trees evolved from the application of the boosting methods to the regression trees. The general idea is to compute a sequence of (extremely) simple trees, where each successive tree is built for the prediction residuals of its preceding tree. The complexity of the Gradient Boosting depends on the number of decision trees,their depth and number of features.\n",
    "\n",
    "#### General applications.\n",
    "\n",
    "The Gradient Boosted Regression Trees (GBRT) is a generalization of boosting to arbitrary differentiable loss functions. The GBRT is an accurate and effective off-the-shelf procedure that can be used for both regression and classification problems.\n",
    "\n",
    "#### Strengths and weakness\n",
    "\n",
    "*Strengths*:\n",
    "\n",
    "- Natural handling of data of the mixed type (= heterogeneous features)\n",
    "- Predictive power\n",
    "- Robustness of outliers in the output space (via robust loss functions)\n",
    "- Robustness of data scaling\n",
    "\n",
    "\n",
    "*Weakness*:\n",
    "\n",
    "- Scalability, since the sequential nature of boosting can hardly be parallelized.\n",
    "\n",
    "#### Justifications\n",
    "\n",
    "- The GradientBoostingClassifier supports both the binary and the multi-label classification\n",
    "- The prediction time is relatively low\n",
    "- It supports the mixed type of features and does not need data normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.107\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00099\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00083\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.146\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00143\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00080\n",
      "Training GradientBoostingClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.186\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00174\n",
      "Predicting labels using GradientBoostingClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00079\n",
      "\n",
      "Gradient Boosting training results\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.794118     1.000000   100   0.00083    0.10686\n",
      "2    0.757576     0.996255   200   0.00080    0.14623\n",
      "3    0.733813     0.970874   300   0.00079    0.18613\n"
     ]
    }
   ],
   "source": [
    "training_set_sizes = [100, 200, 300]\n",
    "boost_table = None\n",
    "i = 1\n",
    "for set_size in training_set_sizes:\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, train_size=set_size, random_state=475)\n",
    "    #X_train, y_train, X_test, y_test = next_batch(rs, train_size=set_size, test_size=num_test, keep_test_set_constant=True)\n",
    "\n",
    "    clf = create_classifier(\"GrBoost\")\n",
    "    \n",
    "\n",
    "    train_time = train_classifier(clf, X_train[:set_size], y_train[:set_size])\n",
    "    f1_training, tr_time = predict_labels(clf, X_train[:set_size], y_train[:set_size])\n",
    "    f1_testing, ts_time = predict_labels(clf, X_test, y_test)\n",
    "    row = {\"Size\":set_size, \"F1_training\":f1_training, \"F1_testing\":f1_testing, \"Time train\":train_time, \"Time test\":ts_time}\n",
    "    boost_table = append_value(boost_table, row, i)\n",
    "    i += 1\n",
    "\n",
    "# Gradient Boosting training results\n",
    "print \"\\nGradient Boosting training results\\n\", boost_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "The training time slowly increases along with the size of the increasing training set. The prediction time fluctuates on the same level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.744526            1   100   0.00029    0.00163\n",
      "2    0.781955            1   200   0.00026    0.00225\n",
      "3    0.688000            1   300   0.00027    0.00348\n",
      "\n",
      "SVM\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.800000     0.901961   100   0.00198    0.00327\n",
      "2    0.812903     0.855305   200   0.00265    0.00738\n",
      "3    0.818182     0.845666   300   0.00362    0.01435\n",
      "\n",
      "Gradient boosting\n",
      "   F1_testing  F1_training  Size Time test Time train\n",
      "1    0.794118     1.000000   100   0.00083    0.10686\n",
      "2    0.757576     0.996255   200   0.00080    0.14623\n",
      "3    0.733813     0.970874   300   0.00079    0.18613\n"
     ]
    }
   ],
   "source": [
    "print \"Decision Tree\"\n",
    "print tree_table\n",
    "\n",
    "print \"\\nSVM\"\n",
    "print svm_table\n",
    "\n",
    "print \"\\nGradient boosting\"\n",
    "print boost_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most appropriate model\n",
    "\n",
    "**The SVM was choosed as most appropriate model for the particular problem**.\n",
    "The SVM was chosen as the most appropriate model for this particular problem.\n",
    "\n",
    "The DecisionTrees model appears overfitted in the case of the given data and the size of it, even though the training and testing time was the lowest in comparison to other models. The DS model was rejected, since with the given data it is overfitting and cannot provide a general model.\n",
    "\n",
    "The Gradient-boosting for the given problem may be used, yet there are no more data to construct a general model. For example, with the data size of 300, the model became overfitted. Although the Gradient Boosting is a white-box model, itcan be used for the staff. The Gradient-boosting was used in case of a training of greater time than other models, although the testing time is the lowest here. The Gradient-boosting was rejected, formore data was needed and the F1 accuracy scored less than for the SVM.\n",
    "\n",
    "In comparison to the available data and resources, the SVM is a more appropriate model and can construct a general model for the particular problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SVM prediction in Layman's terms\n",
    "\n",
    "The SVM is a good choice for the Student intervention problem, where high dimensionality of the data (a large number of descriptive fields) exists. In the future, this dimensionality will probably increase (especially when using an e-learning platform and taking into account the students’ activities); and the SVM’s advantage is its capacity to classify such data.\n",
    "\n",
    "The main idea of the  SVM is to single out the data with boundaries, as it classifies data across different classes well . For example, in our problem we need to classify students into two classes: ones who passed an exam and those who did not. In the learning stage, the SVM tries to find best way to separate the given data for the two classes and builds a mathematical model for further predictions.\n",
    "\n",
    "The best way to understand how the SVM analyzes the data is graphical representation:\n",
    "\n",
    "![\"SVM training\"](separating-lines.png)\n",
    "\n",
    "x1 and x2 are the descriptive information about students. For example, x1 means failures (ranged) and x2– their family status (also ranged). Circles represent students who passed the exam and squares those who did not. The SVN is trying to find (in this example) the linear separator (line) which separates our classes of students best.\n",
    "\n",
    "\n",
    "What does the best separator mean? The figure answers the question:\n",
    "\n",
    "![\"Bondaries of two classes\"](optimal-hyperplane.png)\n",
    "\n",
    "The best separator consists of two lines (boundaries)and circles and squares (in the linear case), designating the two classes which are set apart at a maximal distance from the lines. The circles and the squares on the boundaries are closer to the middle line between boundaries, and are named support vectors.\n",
    "\n",
    "After the SVM finds the maximal boundaries, learning process finishes and the SVM is for use.\n",
    "For some problems, it is not possible to find the best separator (called kernel function) using the linear function. In such situations, the non-linear separator will be used. An example you can see in Figure 3.\n",
    "\n",
    "\n",
    "![\"Non-linear kernel\"](svm_diagram_nonlinear.png)\n",
    "\n",
    "After a new student joins the learning, we already have a lot of data about him/her for making predictions, yet some data is not available and we leave it to the default preferred values. Having such data provided for the SVM model, we can apply the kernel function (linear or nonlinear), using the learned parameters (weights and biases) and the student data vector (prepared student data-field values). The result is the kernel return value of -1 or +1. For example, +1 specifies the class of students who passed the exam and -1, accordingly, those who did not. Such sequence not strict.\n",
    "As mentioned before, in the learning stage the classes were divided by a decision boundary (also named hyperplane), where the points on each side were labeled differently to those on the other side, equal to +1 or -1. Such values for classes have not been chosen arbitrarily, yet mathematically they divide data into two classes. For example, the circles in the Figure 1 in the SVM model is labeled as -1 and squares as +1. \n",
    "\n",
    "\n",
    "### Tuning SVM\n",
    "\n",
    "The following three are the main criteria used for tuning the SVM (SVC function):\n",
    "- C - penalty parameter. It regularizes the estimation if the dataset is noisy (the noisier the data, the more the C value will be increased). Default=1.0.\n",
    "- The kernel function: rbf (default), linear, poly, sigmoid, and custom.\n",
    "- Tolerance - stopping criterion tolerance (default=1e-3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1760 candidates, totalling 17600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done  80 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=16)]: Done 559 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=16)]: Done 978 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=16)]: Done 1678 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=16)]: Done 2390 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=16)]: Done 3490 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=16)]: Done 4990 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=16)]: Done 6115 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=16)]: Done 7884 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=16)]: Done 9608 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=16)]: Done 11350 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=16)]: Done 12907 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=16)]: Done 14844 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=16)]: Done 17559 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=16)]: Done 17600 out of 17600 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: SVC(C=0.80000000000000004, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.0001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "c_range = np.arange(0.8, 1.9,.05)\n",
    "tol_range = np.arange(0.0001, 0.01, 0.0005)\n",
    "gamma = \n",
    "\n",
    "# parameters used with GridSearch for SVM\n",
    "params_dic = {\"C\":c_range, \"kernel\": ['rbf', 'linear', 'poly', 'sigmoid'], \"tol\" : tol_range}\n",
    "\n",
    "# prepare CV \n",
    "cv = StratifiedShuffleSplit(y_train, n_iter = 10, random_state = 42)\n",
    "\n",
    "# create SVM classifier and grid_search, define scorer\n",
    "scorer = make_scorer(f1_score)\n",
    "clf = svm.SVC()\n",
    "grid_search_obj = GridSearchCV(estimator=clf, param_grid=params_dic, scoring=scorer, iid=True, \n",
    "                               cv=cv, verbose=True, n_jobs=16)\n",
    "# Fit data with GridSearch\n",
    "grid_search_obj.fit(X_train, y_train)\n",
    "\n",
    "#get best estimator\n",
    "best_estimator = grid_search_obj.best_estimator_\n",
    "\n",
    "print \"Best parameters:\", best_estimator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score for tuned SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.808\n"
     ]
    }
   ],
   "source": [
    "# Predict data\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "result = f1_score(y_test, y_pred)\n",
    "print \"F1 score: {:.3f}\".format(result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
